{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install hazm\n",
        "import functools\n",
        "import sys\n",
        "import hazm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "axB1ppkSseKC"
      },
      "id": "axB1ppkSseKC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c661e3c4",
      "metadata": {
        "id": "c661e3c4"
      },
      "outputs": [],
      "source": [
        "seed = 0\n",
        "\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/sentipers/final_sentipers_binary.csv', encoding='utf-8')\n",
        "\n",
        "# tokenize data\n",
        "def tokenize(comment):\n",
        "    return hazm.word_tokenize(comment)\n",
        "\n",
        "\n",
        "# creating vocab\n",
        "min_freq = 5\n",
        "data['tokens'] = data['comment'].apply(lambda t: tokenize(t))\n",
        "special_tokens = ['<unk>', '<pad>']\n",
        "vocab = torchtext.vocab.build_vocab_from_iterator(data['tokens'],\n",
        "                                                  min_freq=min_freq,\n",
        "                                                  specials=special_tokens)\n",
        "unk_index = vocab['<unk>']\n",
        "pad_index = vocab['<pad>']\n",
        "vocab.set_default_index(unk_index)\n",
        "\n",
        "# making input ids\n",
        "# comments are in length between 3 and 256, so we do zero padding for those which have a length less than 256\n",
        "def numeralize(tokens):\n",
        "  ids = [vocab[token] for token in tokens]\n",
        "  ids = np.pad(ids, (0, 256 - len(ids)), 'constant')\n",
        "  return ids\n",
        "\n",
        "# making label ids\n",
        "def toId(label):\n",
        "  return 1 if label=='positive' else 0\n",
        "\n",
        "\n",
        "data['ids']=data['tokens'].apply(lambda t: numeralize(t))\n",
        "data['label']=data['label_id'].apply(lambda t: toId(t))\n",
        "data['length']=data['ids'].apply(lambda t: len(t))\n",
        "\n",
        "data = data[['ids','label','length']]\n",
        "\n",
        "\n",
        "new_data = []\n",
        "for [ids,label,length] in data.values:\n",
        "    new_data.append({'ids':torch.tensor(ids),'label':torch.tensor(label),'length':torch.tensor(length)})"
      ],
      "metadata": {
        "id": "hfNEfS97wACp"
      },
      "id": "hfNEfS97wACp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53427b55",
      "metadata": {
        "id": "53427b55"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional,\n",
        "                 dropout_rate, pad_index):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_index)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, bidirectional=bidirectional,\n",
        "                            dropout=dropout_rate, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        \n",
        "    def forward(self, ids, length):\n",
        "        # ids = [batch size, seq len]\n",
        "        # length = [batch size]\n",
        "        embedded = self.dropout(self.embedding(ids))\n",
        "        # embedded = [batch size, seq len, embedding dim]\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, length, batch_first=True, \n",
        "                                                            enforce_sorted=False)\n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "        output, output_length = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        # output = [batch size, seq len, hidden dim * n directions]\n",
        "        if self.lstm.bidirectional:\n",
        "            hidden = self.dropout(torch.cat([hidden[-1], hidden[-2]], dim=-1))\n",
        "            # hidden = [batch size, hidden dim * 2]\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1])\n",
        "            # hidden = [batch size, hidden dim]\n",
        "        prediction = self.fc(hidden)\n",
        "        # prediction = [batch size, output dim]\n",
        "        return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11206188",
      "metadata": {
        "id": "11206188"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 300\n",
        "hidden_dim = 300\n",
        "output_dim = 2\n",
        "n_layers = 2\n",
        "\n",
        "# this argument would be Tru for BiLSTM model\n",
        "bidirectional = False\n",
        "dropout_rate = 0.5\n",
        "batch_size = 16\n",
        "\n",
        "model = LSTM(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout_rate, \n",
        "             pad_index)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5feb9512",
      "metadata": {
        "id": "5feb9512"
      },
      "outputs": [],
      "source": [
        "# counting model params\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3edc8e02",
      "metadata": {
        "id": "3edc8e02"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_normal_(m.weight)\n",
        "        nn.init.zeros_(m.bias)\n",
        "    elif isinstance(m, nn.LSTM):\n",
        "        for name, param in m.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.zeros_(param)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.orthogonal_(param)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "2Whp8i_ElkyL"
      },
      "id": "2Whp8i_ElkyL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "AylR-k-6llRU"
      },
      "id": "AylR-k-6llRU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing fastText\n",
        "vectors = torchtext.vocab.FastText(language='fa')\n",
        "pretrained_embedding = vectors.get_vecs_by_tokens(vocab.get_itos())"
      ],
      "metadata": {
        "id": "Xd63iUauBbhX"
      },
      "id": "Xd63iUauBbhX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate(batch, pad_index):\n",
        "    batch_ids = [i['ids'] for i in batch]\n",
        "    batch_ids = nn.utils.rnn.pad_sequence(batch_ids, padding_value=pad_index, batch_first=True)\n",
        "    batch_length = [i['length'] for i in batch]\n",
        "    batch_length = torch.stack(batch_length)\n",
        "    batch_label = [i['label'] for i in batch]\n",
        "    batch_label = torch.stack(batch_label)\n",
        "    batch = {'ids': batch_ids,\n",
        "             'length': batch_length,\n",
        "             'label': batch_label}\n",
        "    return batch"
      ],
      "metadata": {
        "id": "-0RqZPyd1XHo"
      },
      "id": "-0RqZPyd1XHo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collate = functools.partial(collate, pad_index=pad_index)"
      ],
      "metadata": {
        "id": "48jWiwjw1Y0C"
      },
      "id": "48jWiwjw1Y0C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_op(dataloader, model, criterion, optimizer, device):\n",
        "\n",
        "    model.train()\n",
        "    epoch_losses = 0\n",
        "    epoch_accs = 0\n",
        "\n",
        "\n",
        "    for batch in tqdm(dataloader, desc='training...', file=sys.stdout):\n",
        "        ids = batch['ids'].to(device)\n",
        "        length = batch['length']\n",
        "        label = batch['label'].to(device)\n",
        "        preds = model(ids, length)\n",
        "        loss = criterion(preds, label)\n",
        "        accuracy = get_accuracy(preds, label)\n",
        "        \n",
        "       \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_losses+=loss.item()\n",
        "        epoch_accs+=accuracy.item()\n",
        "\n",
        "\n",
        "    return epoch_losses/len(dataloader), epoch_accs/len(dataloader)"
      ],
      "metadata": {
        "id": "Uo3rN5aT1aqt"
      },
      "id": "Uo3rN5aT1aqt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader, model, criterion, device):\n",
        "    \n",
        "    model.eval()\n",
        "    epoch_losses = 0\n",
        "    epoch_accs = 0\n",
        "    predictions = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc='evaluating...', file=sys.stdout):\n",
        "            ids = batch['ids'].to(device)\n",
        "            length = batch['length']\n",
        "            label = batch['label'].to(device)\n",
        "            preds = model(ids, length)\n",
        "            loss = criterion(preds, label)\n",
        "            accuracy = get_accuracy(preds, label)\n",
        "            \n",
        "            preds = preds.argmax(dim=-1)\n",
        "            predictions.extend(preds)\n",
        "            labels.extend(label)\n",
        "            epoch_losses+=loss.item()\n",
        "            epoch_accs+=accuracy.item()\n",
        "    \n",
        "    predictions = torch.stack(predictions).cpu().detach().numpy()\n",
        "    labels = torch.stack(labels).cpu().detach().numpy()\n",
        "    f_score = f1_score(labels, predictions, average=\"weighted\")\n",
        "    return epoch_losses/len(dataloader), epoch_accs/len(dataloader) , f_score"
      ],
      "metadata": {
        "id": "SW9NwsJe1cu0"
      },
      "id": "SW9NwsJe1cu0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(prediction, label):\n",
        "    batch_size, _ = prediction.shape\n",
        "    predicted_classes = prediction.argmax(dim=-1)\n",
        "    correct_predictions = predicted_classes.eq(label).sum()\n",
        "    accuracy = correct_predictions / batch_size\n",
        "    return accuracy\n",
        "\n",
        "# this accuracy function would be implemented for multi class data\n",
        "def get_multi_accuracy(predictions, label):\n",
        "    top_pred = predictions.argmax(1, keepdim = True)\n",
        "    correct = top_pred.eq(label.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / label.shape[0]\n",
        "    return acc"
      ],
      "metadata": {
        "id": "YA1t6TqA1exB"
      },
      "id": "YA1t6TqA1exB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k=5\n",
        "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
        "foldperf={}\n",
        "\n",
        "n_epochs = 10\n",
        "best_test_loss = float('inf')\n",
        "\n",
        "history = {'train_losses': [], 'test_losses': [],'train_accs':[],'test_accs':[],'test_f1s':[]}\n",
        "\n",
        "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(data)))):\n",
        "    train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "    test_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "    train_dataloader=torch.utils.data.DataLoader(new_data, batch_size=16,collate_fn=collate, sampler=train_sampler)\n",
        "    test_dataloader=torch.utils.data.DataLoader(new_data, batch_size=16,collate_fn=collate, sampler=test_sampler)\n",
        "        \n",
        "    model = LSTM(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout_rate, \n",
        "             pad_index)\n",
        "    model.apply(initialize_weights)\n",
        "\n",
        "    model.embedding.weight.data = pretrained_embedding\n",
        "\n",
        "    lr = 5e-4\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    model = model.to(device)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_op(train_dataloader, model, criterion, optimizer, device)\n",
        "        test_loss, test_acc , test_f1 = evaluate(test_dataloader, model, criterion, device)\n",
        "\n",
        "        \n",
        "        history['train_losses'].append(train_loss)\n",
        "        history['test_losses'].append(test_loss)\n",
        "        history['train_accs'].append(train_acc)\n",
        "        history['test_accs'].append(test_acc)\n",
        "        history['test_f1s'].append(test_f1)\n",
        "\n",
        "        print(f'epoch: {epoch+1}')\n",
        "        print(f'train_loss: {train_loss:.3f}, train_acc: {train_acc:.3f}')\n",
        "        print(f'valid_loss: {test_loss:.3f}, valid_acc: {test_acc:.3f}')\n",
        "\n",
        "    foldperf['fold{}'.format(fold+1)] = history  \n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), 'bilstm.pt')"
      ],
      "metadata": {
        "id": "7GjBNLL41gYW"
      },
      "id": "7GjBNLL41gYW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def average(numList):\n",
        "  return sum(numList)/len(numList)\n",
        "\n",
        "print('accuracy average: ',average(history['test_accs']))\n",
        "print('loss average: ',average(history['test_losses']))\n",
        "print('f1 average: ',average(history['test_f1s']))"
      ],
      "metadata": {
        "id": "GdY7DkY6cyzc"
      },
      "id": "GdY7DkY6cyzc",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "kfold_lstm_fasttext.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}